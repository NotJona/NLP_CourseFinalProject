{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Comparison with DeepSeek API\n",
    "\n",
    "Out of curiosity, let us compare our results to results obtained through an API"
   ],
   "id": "c151de2dfa10ba7f"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "!pip install python-dotenv pandas numpy scikit-learn",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T11:29:20.241115700Z",
     "start_time": "2025-08-24T10:43:17.367358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import numpy as np\n",
    "import re\n",
    "import ast\n",
    "from sklearn.metrics import f1_score"
   ],
   "id": "3b375477b318779c",
   "outputs": [],
   "execution_count": 132
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# First we have to load our data",
   "id": "e8ec0b0c1f38fe11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T08:44:57.609301Z",
     "start_time": "2025-08-24T08:44:57.592489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_jsonl(file_path):\n",
    "    \"\"\"\n",
    "    Load a JSONL file and return a list of JSON objects.\n",
    "    :param file_path: str, path to the JSONL file\n",
    "    :return: list of dicts, each representing a JSON object\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    return data"
   ],
   "id": "abc30e0d5a8f911b",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T08:44:57.616507Z",
     "start_time": "2025-08-24T08:44:57.609301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_file_path = 'data_germeval/train.jsonl'\n",
    "dev_file_path = 'data_germeval/development.jsonl'\n",
    "test_file_path = 'data_germeval/test.jsonl'"
   ],
   "id": "6c03293e92f22d42",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T08:44:57.686865Z",
     "start_time": "2025-08-24T08:44:57.619058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = load_jsonl(train_file_path)\n",
    "dev_data = load_jsonl(dev_file_path)\n",
    "test_data = load_jsonl(test_file_path)"
   ],
   "id": "ed32551fa2b6b175",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Second we have to generate the bins as in germeval.ipybn",
   "id": "5a1f1a88fabef155"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T08:54:48.518339Z",
     "start_time": "2025-08-24T08:54:48.504969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def assign_bin_maj(item, is_test=False):\n",
    "    \"\"\"\n",
    "    takes a tweet and its annotations (if available) and computes 1 if a majority of annotators assigned a label other than 0-Kein, predicts 0 if a majority assigned 0-Kein. If there was no majority, either label is considered correct for evaluation.\n",
    "    :param item: dictionary of the form {'id': , 'text': , 'annotators': }\n",
    "    :param is_test: if False annotations are available. If True not\n",
    "    :return: label\n",
    "    \"\"\"\n",
    "    if not is_test:\n",
    "        labels = [ann['label'] for ann in item['annotations']]\n",
    "        label_counts = Counter(labels)\n",
    "        majority_label, majority_count = label_counts.most_common(1)[0]\n",
    "        bin_maj_label = 1 if majority_label != '0-Kein' else 0\n",
    "    else:\n",
    "        bin_maj_label = None\n",
    "    return bin_maj_label\n",
    "    \n",
    "def assign_bin_one(item, is_test=False):\n",
    "    \"\"\"\n",
    "    takes a tweet and its annotations (if available) and computes 1 if at least one annotator assigned a label other than 0-Kein, 0 otherwise.\n",
    "    :param item: dictionary of the form {'id': , 'text': , 'annotators': }\n",
    "    :param is_test: if False annotations are available. If True not\n",
    "    :return: label\n",
    "    \"\"\"\n",
    "    if not is_test:\n",
    "        bin_one_label = 1 if any(ann['label'] != '0-Kein' for ann in item['annotations']) else 0\n",
    "    else:\n",
    "        bin_one_label = None\n",
    "    return bin_one_label\n",
    "\n",
    "def assign_bin_all(item, is_test=False):\n",
    "    \"\"\"\n",
    "    takes a tweet and its annotations (if available) and computes 1 if all annotators assigned labels other than 0-Kein, 0 otherwise.\n",
    "    :param item: dictionary of the form {'id': , 'text': , 'annotators': }\n",
    "    :param is_test: if False annotations are available. If True not\n",
    "    :return: label\n",
    "    \"\"\"\n",
    "    if not is_test:\n",
    "        bin_all_label = 1 if all(ann['label'] != '0-Kein' for ann in item['annotations']) else 0\n",
    "    else:\n",
    "        bin_all_label = None\n",
    "    return bin_all_label\n",
    "\n",
    "def assign_multi_maj(item, is_test=False):\n",
    "    \"\"\"\n",
    "    takes a tweet and its annotations (if available) and predicts the majority label if there is one, if there is no majority label, any of the labels assigned is counted as a correct prediction for evaluation.\n",
    "    :param item: dictionary of the form {'id': , 'text': , 'annotators': }\n",
    "    :param is_test: if False annotations are available. If True not\n",
    "    :return: label\n",
    "    \"\"\"\n",
    "    if not is_test:\n",
    "        labels = [ann['label'] for ann in item['annotations']]\n",
    "        label_counts = Counter(labels)\n",
    "        majority_label, majority_count = label_counts.most_common(1)[0]\n",
    "        multi_maj_label = majority_label if majority_count > len(labels) / 2 else labels[0]\n",
    "        multi_maj_label = int(multi_maj_label.split('-')[0])\n",
    "    else:\n",
    "        multi_maj_label = None\n",
    "    return multi_maj_label\n",
    "\n",
    "def assign_disagree_bin(item, is_test=False):\n",
    "    \"\"\"\n",
    "    takes a tweet and its annotations (if available) and predicts 1 if there is a disagreement between annotators on 0-Kein versus all other labels and 0 otherwise.\n",
    "    :param item: dictionary of the form {'id': , 'text': , 'annotators': }\n",
    "    :param is_test: if False annotations are available. If True not\n",
    "    :return: label\n",
    "    \"\"\"\n",
    "    if not is_test:\n",
    "        labels = [ann['label'] for ann in item['annotations']]\n",
    "        unique_labels = set(labels)\n",
    "        disagree_bin_label = 1 if '0-Kein' in unique_labels and len(unique_labels) > 1 else 0\n",
    "    else:\n",
    "        disagree_bin_label = None\n",
    "    return disagree_bin_label"
   ],
   "id": "f63d53fab89920dc",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T08:56:36.912014Z",
     "start_time": "2025-08-24T08:56:36.898950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def total_data(item, is_test=False):\n",
    "    \"\"\"\n",
    "    collects all labels described above for one tweet.\n",
    "    :param item: dictionary of the form {'id': , 'text': , 'annotators': }\n",
    "    :param is_test: if False annotations are available. If True not\n",
    "    :return: dictionary of the form {'id': , 'text': , 'bin_maj_label':, 'bin_one_label': , ... }\n",
    "    \"\"\"\n",
    "    text = item['text']\n",
    "    text = text.replace('\\n', ' ')\n",
    "    return {'id': item['id'], 'text': text, 'bin_maj_label': assign_bin_maj(item), 'bin_one_label': assign_bin_one(item),\n",
    "            'bin_all_label': assign_bin_all(item), 'multi_maj_label': assign_multi_maj(item), \n",
    "            'disagree_bin_label': assign_disagree_bin(item)}"
   ],
   "id": "6b55753e45ed1b49",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T09:27:16.968171Z",
     "start_time": "2025-08-24T09:27:16.953340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def combine_data(data, dataframe = False):\n",
    "    \"\"\"\n",
    "    iterates over a list of tweets and annotations\n",
    "    :param data: list of dictionaries\n",
    "    :return: list of dictionaries or dataframe\n",
    "    \"\"\"\n",
    "    data_with_labels = [total_data(item) for item in data]\n",
    "    if dataframe:\n",
    "        header = data_with_labels[0].keys()\n",
    "        data_with_labels = pd.DataFrame(data_with_labels, columns=header)\n",
    "    return data_with_labels\n",
    "        "
   ],
   "id": "d73dbd14537b4326",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_data_labeled = combine_data(train_data)",
   "id": "82a9690a1f5f02a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T10:37:16.198593Z",
     "start_time": "2025-08-24T10:37:16.153234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dev_data_labeled = combine_data(dev_data)\n",
    "dev_df = combine_data(dev_data, dataframe = True)"
   ],
   "id": "fa2f0e5469cc1784",
   "outputs": [],
   "execution_count": 131
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Now the API part",
   "id": "63b5c1363b1661ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T09:08:54.706679Z",
     "start_time": "2025-08-24T09:08:54.683464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "DEEPSEEK_API_KEY = os.getenv(\"DEEPSEEK_API_KEY_25\")\n",
    "print(f\"API Key loaded: {DEEPSEEK_API_KEY is not None}\")"
   ],
   "id": "c79e122518898bde",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded: True\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's first do it the 'simple' way: We directly provide the AI with a few examples and check what it does.",
   "id": "466f9cb1e1b64c3b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's do a test",
   "id": "8bbd6709dcf68649"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T11:07:30.983315Z",
     "start_time": "2025-08-24T11:07:30.969144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "len_train = len(train_data_labeled)\n",
    "random_indices = np.random.randint(0, len_train, size=100) \n",
    "example_texts = [train_data_labeled[i] for i in random_indices]\n",
    "prompt_english = f\"\"\"\n",
    "**Task:** Predict sexism annotation labels for a new text based on the following label definitions.\n",
    "\n",
    "**Label Definitions:**\n",
    "- 'bin_maj_label': A majority of annotators found the text to be sexist.\n",
    "- 'bin_one_label': At least one annotator found the text to be sexist.\n",
    "- 'bin_all_label': All annotators found the text to be sexist.\n",
    "- 'multi_maj_label': The multi-class label (integer from 0 to 4) that the most annotators assigned.\n",
    "- 'disagree_bin_label': The annotators disagreed on the binary (sexist/not sexist) classification.\n",
    "\n",
    "**Examples from the Dataset:**\n",
    "{chr(10).join(str(example) for example in example_texts)}\n",
    "\n",
    "**Text to Analyze:**\n",
    "'{dev_data_labeled[4]['text']}'\n",
    "\n",
    "**Instructions:**\n",
    "Analyze the text above and predict its labels. Return ONLY a valid Python dictionary in the following format:\n",
    "{{'bin_maj_label': <value>, 'bin_one_label': <value>, 'bin_all_label': <value>, 'multi_maj_label': <value>, 'disagree_bin_label': <value>}}\n",
    "\"\"\""
   ],
   "id": "37e836d69b810ebb",
   "outputs": [],
   "execution_count": 182
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T11:07:39.733092Z",
     "start_time": "2025-08-24T11:07:31.746280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "api_url = \"https://api.deepseek.com/v1/chat/completions\"  \n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {DEEPSEEK_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"model\": \"deepseek-chat\", \n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": prompt_english},\n",
    "    ],\n",
    "    \"max_tokens\": 70\n",
    "}\n",
    "response = requests.post(api_url, headers=headers, json=data)"
   ],
   "id": "12aa0e91b21d4a38",
   "outputs": [],
   "execution_count": 183
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T11:07:39.763666Z",
     "start_time": "2025-08-24T11:07:39.754882Z"
    }
   },
   "cell_type": "code",
   "source": "response.json()['choices'][0]['message']['content']",
   "id": "25ce8ec5de3da3b0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'bin_maj_label': 1, 'bin_one_label': 1, 'bin_all_label': 0, 'multi_maj_label': 2, 'disagree_bin_label': 1}\""
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 184
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's generalize",
   "id": "486a41a80f857b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T15:32:36.534605Z",
     "start_time": "2025-08-24T15:32:36.509009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Do we want to use the API?\n",
    "generate = False"
   ],
   "id": "a46121257b47c48e",
   "outputs": [],
   "execution_count": 343
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T12:46:32.040663Z",
     "start_time": "2025-08-24T12:46:32.035346Z"
    }
   },
   "cell_type": "code",
   "source": "len_train = len(train_data_labeled)",
   "id": "6f952f9b77478a29",
   "outputs": [],
   "execution_count": 252
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T13:20:16.976068Z",
     "start_time": "2025-08-24T13:20:16.962172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pattern_1 = r\"\\{'bin_maj_label':\\s*(\\d),\\s*'bin_one_label':\\s*(\\d),\\s*'bin_all_label':\\s*(\\d),\\s*'multi_maj_label':\\s*(\\d),\\s*'disagree_bin_label':\\s*(\\d)\\}\"\n",
    "pattern_2 = r\"\\{\\\\\\s*n\\s*'bin_maj_label':\\s*(\\d),\\s*\\\\\\s*n\\s*'bin_one_label':\\s*(\\d),\\s*\\\\\\s*n\\s*'bin_all_label':\\s*(\\d),\\s*\\\\\\s*n\\s*'multi_maj_label':\\s*(\\d),\\s*\\\\\\s*n\\s*'disagree_bin_label':\\s*(\\d)\\s*\\\\\\s*n\\s*\\}\""
   ],
   "id": "2149c89a39090bba",
   "outputs": [],
   "execution_count": 321
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T13:20:18.997103Z",
     "start_time": "2025-08-24T13:20:18.992699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_dict_from_response(response_string):\n",
    "    match1 = re.search(pattern_1, response_string, re.DOTALL)\n",
    "    match2 = re.search(pattern_2, response_string, re.DOTALL)\n",
    "    if match1:\n",
    "        dict_str = match1.group(0)\n",
    "        result_dict = ast.literal_eval(dict_str)\n",
    "        return [True, result_dict]\n",
    "    elif match2:\n",
    "        dict_str = match2.group(0)\n",
    "        result_dict = ast.literal_eval(dict_str)\n",
    "        return [True, result_dict]   \n",
    "    else:\n",
    "        print(\"No dictionary pattern found in the response.\")\n",
    "        print(response_string)\n",
    "        return [False]"
   ],
   "id": "619fb38219fb441",
   "outputs": [],
   "execution_count": 322
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T15:23:07.977790Z",
     "start_time": "2025-08-24T15:23:07.960047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(lbls, preds):\n",
    "    f1 = f1_score(lbls, preds, average='weighted')\n",
    "    return {'f1': f1}\n",
    "\n",
    "def compute_f1(real_data, prediction):\n",
    "    print(f\"Dev set F1 score Bin Maj: {compute_metrics(real_data['bin_maj_label'], prediction['bin_maj_label'])['f1']}\")\n",
    "    print(f\"Dev set F1 score Bin One: {compute_metrics(real_data['bin_one_label'], prediction['bin_one_label'])['f1']}\")\n",
    "    print(f\"Dev set F1 score Bin All: {compute_metrics(real_data['bin_all_label'], prediction['bin_all_label'])['f1']}\")\n",
    "    print(f\"Dev set F1 score Multi Maj: {compute_metrics(real_data['multi_maj_label'], prediction['multi_maj_label'])['f1']}\")\n",
    "    print(\n",
    "        f\"Dev set F1 score Disagree Bin: {compute_metrics(real_data['disagree_bin_label'], prediction['disagree_bin_label'])['f1']}\")"
   ],
   "id": "f0682fd9df279305",
   "outputs": [],
   "execution_count": 338
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Zero Shot:",
   "id": "ebd20f7ceeb84fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T13:34:31.802375Z",
     "start_time": "2025-08-24T13:34:31.796129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_prompt_zero_shot(text_to_analyze):\n",
    "    prompt = f\"\"\"\n",
    "    **Task:** Predict sexism annotation labels for a new text based on the following label definitions.\n",
    "    \n",
    "    **Label Definitions:**\n",
    "    - 'bin_maj_label': A majority of annotators found the text to be sexist.\n",
    "    - 'bin_one_label': At least one annotator found the text to be sexist.\n",
    "    - 'bin_all_label': All annotators found the text to be sexist.\n",
    "    - 'multi_maj_label': The multi-class label (integer from 0 to 4) that the most annotators assigned.\n",
    "    - 'disagree_bin_label': The annotators disagreed on the binary (sexist/not sexist) classification.\n",
    "    \n",
    "    **Text to Analyze:**\n",
    "    '{text_to_analyze}'\n",
    "    \n",
    "    **Instructions:**\n",
    "    Analyze the text above and predict its labels. Return ONLY a valid Python dictionary in exactly the following format \n",
    "    (no spaces or newlines!):\n",
    "    {{'bin_maj_label': <value>, 'bin_one_label': <value>, 'bin_all_label': <value>, 'multi_maj_label': <value>, 'disagree_bin_label': <value>}}\n",
    "    \"\"\"\n",
    "    return prompt"
   ],
   "id": "4649591b836b0ec2",
   "outputs": [],
   "execution_count": 332
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T13:34:33.866692Z",
     "start_time": "2025-08-24T13:34:33.858057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_labels_zero_shot(text_to_analyze):\n",
    "    api_url = \"https://api.deepseek.com/v1/chat/completions\"  \n",
    "    headers = {\n",
    "    \"Authorization\": f\"Bearer {DEEPSEEK_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    prompt = get_prompt_zero_shot(text_to_analyze)\n",
    "    dat = {\n",
    "    \"model\": \"deepseek-chat\", \n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ],\n",
    "    \"max_tokens\": 70\n",
    "    }\n",
    "    respo = requests.post(api_url, headers=headers, json=dat)\n",
    "    return respo.json()['choices'][0]['message']['content']"
   ],
   "id": "2f8d0441dc232eb4",
   "outputs": [],
   "execution_count": 333
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T13:34:34.517922Z",
     "start_time": "2025-08-24T13:34:34.503349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def eval_string_zero_shot(item):\n",
    "    #print(item)\n",
    "    result = generate_labels_zero_shot(item['text'])\n",
    "    result = extract_dict_from_response(result)\n",
    "    while not result[0]:\n",
    "        result = extract_dict_from_response(generate_labels_zero_shot(item['text']))\n",
    "    eval_dict = dict()\n",
    "    eval_dict['id'] = item['id']\n",
    "    eval_dict['text'] = item['text']\n",
    "    eval_dict.update(result[1])\n",
    "    return eval_dict"
   ],
   "id": "4abff595385beac",
   "outputs": [],
   "execution_count": 334
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if generate:\n",
    "    dev_data_predicted_0 = [eval_string_zero_shot(item) for item in dev_data[:100]]\n",
    "    dev_df_predicted_0 = pd.DataFrame(dev_data_predicted_0, columns=dev_data_predicted_0[0].keys())"
   ],
   "id": "62b5be62e9c715cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T15:23:13.078120Z",
     "start_time": "2025-08-24T15:23:13.049839Z"
    }
   },
   "cell_type": "code",
   "source": "compute_f1(dev_df.iloc[:100], dev_df_predicted_0)",
   "id": "20814d0a2eb48c88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev set F1 score Bin Maj: 0.6966680446465482\n",
      "Dev set F1 score Bin One: 0.749474527074367\n",
      "Dev set F1 score Bin All: 0.8238297872340425\n",
      "Dev set F1 score Multi Maj: 0.5660397497239602\n",
      "Dev set F1 score Disagree Bin: 0.6165782044042915\n"
     ]
    }
   ],
   "execution_count": 339
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "These results are ok, but maybe we can improve them by giving DeepSeek some examples?",
   "id": "eee21508edb1f076"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# One Shot",
   "id": "57a3359b8916b66"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T11:44:49.793766Z",
     "start_time": "2025-08-24T11:44:49.784202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_prompt(text_to_analyze, num_examples):\n",
    "    random_indices = np.random.randint(0, len_train, size=num_examples) \n",
    "    example_texts = [train_data_labeled[i] for i in random_indices]\n",
    "    prompt = f\"\"\"\n",
    "    **Task:** Predict sexism annotation labels for a new text based on the following label definitions.\n",
    "    \n",
    "    **Label Definitions:**\n",
    "    - 'bin_maj_label': A majority of annotators found the text to be sexist.\n",
    "    - 'bin_one_label': At least one annotator found the text to be sexist.\n",
    "    - 'bin_all_label': All annotators found the text to be sexist.\n",
    "    - 'multi_maj_label': The multi-class label (integer from 0 to 4) that the most annotators assigned.\n",
    "    - 'disagree_bin_label': The annotators disagreed on the binary (sexist/not sexist) classification.\n",
    "    \n",
    "    **Examples from the Dataset:**\n",
    "    {chr(10).join(str(example) for example in example_texts)}\n",
    "    \n",
    "    **Text to Analyze:**\n",
    "    '{text_to_analyze}'\n",
    "    \n",
    "    **Instructions:**\n",
    "    Analyze the text above and predict its labels. Return ONLY a valid Python dictionary in exactly the following format \n",
    "    (no spaces or newlines!):\n",
    "    {{'bin_maj_label': <value>, 'bin_one_label': <value>, 'bin_all_label': <value>, 'multi_maj_label': <value>, 'disagree_bin_label': <value>}}\n",
    "    \"\"\"\n",
    "    return prompt"
   ],
   "id": "4c4a56860f0dcd24",
   "outputs": [],
   "execution_count": 229
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T11:44:50.187126Z",
     "start_time": "2025-08-24T11:44:50.179830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_labels(text_to_analyze, num_examples):\n",
    "    api_url = \"https://api.deepseek.com/v1/chat/completions\"  \n",
    "    headers = {\n",
    "    \"Authorization\": f\"Bearer {DEEPSEEK_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    prompt = get_prompt(text_to_analyze, num_examples)\n",
    "    dat = {\n",
    "    \"model\": \"deepseek-chat\", \n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ],\n",
    "    \"max_tokens\": 70\n",
    "    }\n",
    "    respo = requests.post(api_url, headers=headers, json=dat)\n",
    "    return respo.json()['choices'][0]['message']['content']"
   ],
   "id": "a603d8bdba7d778b",
   "outputs": [],
   "execution_count": 230
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T13:10:31.240698Z",
     "start_time": "2025-08-24T13:10:31.229932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def eval_string(item, num_examples):\n",
    "    #print(item)\n",
    "    result = extract_dict_from_response(generate_labels(item['text'], num_examples))\n",
    "    while not result[0]:\n",
    "        result = extract_dict_from_response(generate_labels(item['text'], num_examples))\n",
    "    eval_dict = dict()\n",
    "    eval_dict['id'] = item['id']\n",
    "    eval_dict['text'] = item['text']\n",
    "    eval_dict.update(result[1])\n",
    "    return eval_dict"
   ],
   "id": "652a686afeed46c0",
   "outputs": [],
   "execution_count": 307
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if generate:\n",
    "    dev_data_predicted = [eval_string(item, 100) for item in dev_data[:100]]\n",
    "    dev_df_predicted = pd.DataFrame(dev_data_predicted, columns = dev_data_predicted[0].keys())"
   ],
   "id": "20f3752fa4906948",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T15:24:07.921966Z",
     "start_time": "2025-08-24T15:24:07.886763Z"
    }
   },
   "cell_type": "code",
   "source": "compute_f1(dev_df.iloc[:100], dev_df_predicted)",
   "id": "c0b6ca75f1f85847",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev set F1 score Bin Maj: 0.8191471215351812\n",
      "Dev set F1 score Bin One: 0.8200720288115246\n",
      "Dev set F1 score Bin All: 0.8238297872340425\n",
      "Dev set F1 score Multi Maj: 0.7006038647342995\n",
      "Dev set F1 score Disagree Bin: 0.7059975520195839\n"
     ]
    }
   ],
   "execution_count": 340
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Pro: Results not bad\n",
    "Contra: Took quite a while and costs a bit (0.5$). Can we do it with less examples?"
   ],
   "id": "d4fb07c2f5f427b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if generate:\n",
    "    dev_data_predicted_5 = [eval_string(item, 5) for item in dev_data[:100]]\n",
    "    dev_df_predicted_5 = pd.DataFrame(dev_data_predicted_5, columns = dev_data_predicted_5[0].keys())"
   ],
   "id": "574399d28c34d16d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if generate:\n",
    "    dev_data_predicted_10 = [eval_string(item, 10) for item in dev_data[:100]]\n",
    "    dev_df_predicted_10 = pd.DataFrame(dev_data_predicted_10, columns=dev_data_predicted_10[0].keys())"
   ],
   "id": "c2e64451a8808723",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T15:24:20.735768Z",
     "start_time": "2025-08-24T15:24:20.708388Z"
    }
   },
   "cell_type": "code",
   "source": "compute_f1(dev_df.iloc[:100], dev_df_predicted_5)",
   "id": "ba65d378bc84a2be",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev set F1 score Bin Maj: 0.78288\n",
      "Dev set F1 score Bin One: 0.82991499149915\n",
      "Dev set F1 score Bin All: 0.813763440860215\n",
      "Dev set F1 score Multi Maj: 0.6724038713910762\n",
      "Dev set F1 score Disagree Bin: 0.735386189258312\n"
     ]
    }
   ],
   "execution_count": 341
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-24T15:24:22.741185Z",
     "start_time": "2025-08-24T15:24:22.714509Z"
    }
   },
   "cell_type": "code",
   "source": "compute_f1(dev_df.iloc[:100], dev_df_predicted_10)",
   "id": "bd37282d6c01ceb0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev set F1 score Bin Maj: 0.8109375\n",
      "Dev set F1 score Bin One: 0.8197839135654261\n",
      "Dev set F1 score Bin All: 0.8596756756756757\n",
      "Dev set F1 score Multi Maj: 0.676089427891324\n",
      "Dev set F1 score Disagree Bin: 0.7157851662404093\n"
     ]
    }
   ],
   "execution_count": 342
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The 5 examples version is slightly worse than the 10 examples version. The 10 examples version is slightly worse than the 100 examples version.\n",
    "10 examples seem to be a good number of examples as performance is almost as good as the 100 example version. The 10 example version cost ~0.1$"
   ],
   "id": "8fa035a46840dd67"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Pro: Results are better than the prediction of the fine-tuned BERT models.\n",
    "Contra: There are probably issues with reproducibility. One would have to average over many more predictions to truly know if the API yields reliable results."
   ],
   "id": "38bfbfe1490bb35b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
