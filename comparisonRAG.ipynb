{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let us also check what RAG's can do for this project",
   "id": "60cf76461b7ca953"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Thing is, with the API alone, not all examples could be processed (prompt would have been too big). RAG could solve this problem...",
   "id": "f14abea909a80add"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "!pip install python-dotenv pandas llama-index langchain langchain-community llama-index-embeddings-langchain  sentence-transformers",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:55:13.867555Z",
     "start_time": "2025-08-25T13:55:09.759384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from llama_index.core import VectorStoreIndex, StorageContext, load_index_from_storage\n",
    "from llama_index.core.schema import TextNode\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from collections import Counter"
   ],
   "id": "8b1c9ecd75350c2d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:55:15.485789Z",
     "start_time": "2025-08-25T13:55:14.124692Z"
    }
   },
   "cell_type": "code",
   "source": "from functions import load_jsonl, combine_data, compute_f1",
   "id": "40501ab782ce2479",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# The usual setup",
   "id": "99eb85c4fb8299a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:55:15.624996Z",
     "start_time": "2025-08-25T13:55:15.497814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_file_path = 'data_germeval/train.jsonl'\n",
    "dev_file_path = 'data_germeval/development.jsonl'\n",
    "test_file_path = 'data_germeval/test.jsonl'\n",
    "train_data = load_jsonl(train_file_path)\n",
    "dev_data = load_jsonl(dev_file_path)"
   ],
   "id": "e55826622930e068",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:55:15.703947Z",
     "start_time": "2025-08-25T13:55:15.635082Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data_labeled = combine_data(train_data)\n",
    "train_df = combine_data(train_data, dataframe = True)"
   ],
   "id": "252dd8e3044bdab1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MAIN PART",
   "id": "1b04762985ff8db5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's get started with LlamaIndex",
   "id": "2cbb6ed6845a8d68"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "What is happening here? Basically, we transform our textdata into vector representations. Then, given a new text element, we retrieve the most similar text elements (by comparing vector similarity) and average over the labels of the most similar ones. ",
   "id": "d8bedd7dd0f3788b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This method relies on a huggingface model for the embedding. Also, we don't send our data to any LLM for it to predict a label based on the retrieved information. Hence, we don't get input form the LLM (though we might want it, depending on the performance of this code) and no API is needed.",
   "id": "55c0516df70dc70e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:55:15.720451Z",
     "start_time": "2025-08-25T13:55:15.714730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_training_nodes(df):\n",
    "    \"\"\"\n",
    "    Prepares our data for indexing.\n",
    "    :param df: dataframe \n",
    "    :return: TextNode object of our dataframe\n",
    "    \"\"\"\n",
    "    training_nodes = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        text_content = f\"\"\"\n",
    "        Example Text: {row['text']}\n",
    "        \"\"\"\n",
    "        \n",
    "        node = TextNode(\n",
    "        text=text_content,\n",
    "        metadata={\n",
    "        'original_text': row['text'],\n",
    "        'bin_maj_label': row['bin_maj_label'],\n",
    "        'bin_one_label': row['bin_one_label'],\n",
    "        'bin_all_label': row['bin_all_label'],\n",
    "        'multi_maj_label': row['multi_maj_label'],\n",
    "        'disagree_bin_label': row['disagree_bin_label'],\n",
    "        'index': index\n",
    "        }\n",
    "        )\n",
    "        training_nodes.append(node)\n",
    "    \n",
    "    return training_nodes"
   ],
   "id": "da1c816bbec32b05",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:55:15.733551Z",
     "start_time": "2025-08-25T13:55:15.729404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_index(load_path, embed_model):\n",
    "    \"\"\"\n",
    "    Loads precomputed index\n",
    "    :param load_path: str, path to precomputed index\n",
    "    :param embed_model: model to use for embeddings\n",
    "    :return: loaded index \n",
    "    \"\"\"\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=load_path)\n",
    "    index = load_index_from_storage(\n",
    "        storage_context, \n",
    "        embed_model=embed_model\n",
    "    )\n",
    "    print(f\"Index loaded from {load_path}!\")\n",
    "    return index"
   ],
   "id": "9c16a227454055b8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:55:15.747278Z",
     "start_time": "2025-08-25T13:55:15.742317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_reload_vector_index(nodes, model):\n",
    "    \"\"\"\n",
    "    Creates or reloads a vector index using our nodes and LlamaIndex\n",
    "    :param nodes: list of nodes \n",
    "    :param model: str, indicates model to use for embeddings\n",
    "    :return: generated or reloaded index\n",
    "    \"\"\"\n",
    "    if model == \"Bert\":\n",
    "        save_path = \"vector_index_BERT\"\n",
    "        embed_model = HuggingFaceEmbeddings(model_name=\"dbmdz/bert-base-german-uncased\")\n",
    "    else:\n",
    "        save_path = \"vector_index_multilingual-e5\"\n",
    "        embed_model = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large\")\n",
    "        \n",
    "    if os.path.exists(save_path):\n",
    "        print(\"Loading existing index...\")\n",
    "        return load_index(save_path, embed_model)\n",
    "    else:\n",
    "        print(\"Creating index...\")\n",
    "        index = VectorStoreIndex(\n",
    "            nodes,\n",
    "            embed_model=embed_model\n",
    "        )\n",
    "        \n",
    "        index.storage_context.persist(persist_dir=save_path)\n",
    "        print(f\"Index saved to {save_path}!\")\n",
    "        \n",
    "        return index"
   ],
   "id": "696db1415e47adb3",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:55:15.761304Z",
     "start_time": "2025-08-25T13:55:15.756687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def retrieve_similar_examples(query_text, index, top_k=5):\n",
    "    \"\"\"\n",
    "    Retrieves similar examples using LlamaIndex\n",
    "    :param query_text: str, query text\n",
    "    :param index: index to use to retrieve similar examples\n",
    "    :param top_k: int, number of similar examples\n",
    "    :return: list of similar examples\n",
    "    \"\"\"\n",
    "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "    similar_nodes = retriever.retrieve(query_text)\n",
    "\n",
    "    results = []\n",
    "    for node in similar_nodes:\n",
    "        results.append({\n",
    "            'text': node.node.text,\n",
    "            'metadata': node.node.metadata,\n",
    "            'similarity_score': node.score\n",
    "        })\n",
    "    \n",
    "    return results"
   ],
   "id": "b9c8bdf0b58c151f",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:55:15.776249Z",
     "start_time": "2025-08-25T13:55:15.770980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def weighted_aggregation(value_list, similarity_scores):\n",
    "    \"\"\"\n",
    "    computes the weighted average of value_list\n",
    "    :param value_list: list of values \n",
    "    :param similarity_scores: list of similarity scores corresponding to the values\n",
    "    :return: float \n",
    "    \"\"\"\n",
    "    return round(sum(val * score for val, score in zip(value_list, similarity_scores)) / sum(similarity_scores))"
   ],
   "id": "6d7b084018974717",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:55:15.788859Z",
     "start_time": "2025-08-25T13:55:15.785239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def majority_aggregation(value_list):\n",
    "    \"\"\"\n",
    "    Computes the majority vote of value_list\n",
    "    :param value_list: list of values\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    return Counter(value_list).most_common(1)[0][0]"
   ],
   "id": "57df4b9fca031076",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:55:15.804793Z",
     "start_time": "2025-08-25T13:55:15.799625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_from_similar_examples(similar_examples, aggregation='majority'):\n",
    "    \"\"\"\n",
    "    Predict target value from similar examples\n",
    "    :param similar_examples: list of similar examples\n",
    "    :param aggregation: str, aggregation method\n",
    "    :return: list of predictions\n",
    "    \"\"\"\n",
    "    if not similar_examples:\n",
    "        return None\n",
    "\n",
    "    target_values = [[ex['metadata']['bin_maj_label'] for ex in similar_examples],\n",
    "                     [ex['metadata']['bin_one_label'] for ex in similar_examples],\n",
    "                     [ex['metadata']['bin_all_label'] for ex in similar_examples],\n",
    "                     [ex['metadata']['multi_maj_label'] for ex in similar_examples],\n",
    "                     [ex['metadata']['disagree_bin_label'] for ex in similar_examples]]\n",
    "    similarity_scores = [ex['similarity_score'] for ex in similar_examples]\n",
    "    \n",
    "    if aggregation == 'weighted':\n",
    "        return [weighted_aggregation(target_values, similarity_scores) for target_values in target_values]\n",
    "    \n",
    "    elif aggregation == 'majority':\n",
    "        return [majority_aggregation(target_values) for target_values in target_values]\n",
    "        "
   ],
   "id": "aaf79c0895fb1acf",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:55:15.821809Z",
     "start_time": "2025-08-25T13:55:15.816238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_rag_pipeline(df, test_texts, model, top_k=5, aggregation='majority'):\n",
    "    \"\"\"\n",
    "    Complete RAG pipeline using LlamaIndex\n",
    "    :param df: reference dataframe with text elements and labels\n",
    "    :param test_texts: list of test texts\n",
    "    :param model: str indicating which model to use for embeddings. If 'Bert', uses \"dbmdz/bert-base-german-uncased\", else \"intfloat/multilingual-e5-large\"\n",
    "    :param top_k: int, number of similar examples\n",
    "    :param aggregation: str, aggregation method\n",
    "    :return list of dictionaries of the form: {'query_text': , 'prediction':, 'num_similar_examples': 'similar_examples': }  \n",
    "    \"\"\"\n",
    "    print(\"Step 1: Preparing training nodes...\")\n",
    "    training_nodes = prepare_training_nodes(df)\n",
    "    \n",
    "    print(\"Step 2: Creating vector index...\")\n",
    "    index = create_reload_vector_index(training_nodes, model)\n",
    "    \n",
    "    print(\"Step 3: Making predictions...\")\n",
    "    predictions = []\n",
    "    \n",
    "    for test_text in test_texts:\n",
    "        similar_examples = retrieve_similar_examples(test_text, index, top_k)\n",
    "       \n",
    "        prediction = predict_from_similar_examples(similar_examples, aggregation)\n",
    "        predictions.append({\n",
    "            'query_text': test_text,\n",
    "            'prediction': prediction,\n",
    "            'num_similar_examples': len(similar_examples),\n",
    "            'similar_examples': similar_examples[:2] \n",
    "        })\n",
    "    \n",
    "    return predictions"
   ],
   "id": "63802a65f7d3bb31",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's test this",
   "id": "36c84f1e45677e7e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:55:15.843902Z",
     "start_time": "2025-08-25T13:55:15.830365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dev_data_labeled = combine_data(dev_data)\n",
    "dev_df = combine_data(dev_data, dataframe = True)\n",
    "test_data = [dev_data_labeled[i]['text'] for i in range(100)]"
   ],
   "id": "39d4ef71b3013528",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:55:15.858749Z",
     "start_time": "2025-08-25T13:55:15.854299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def data_to_dataframe(prediction):\n",
    "    \"\"\"\n",
    "    takes the output of run_rag_pipeline and turns it into a pandas dataframe with fitting columns for comparison\n",
    "    :param prediction: list of dictionaries (output of run_rag_pipeline)\n",
    "    :return: dataframe\n",
    "    \"\"\"\n",
    "    prediction = [{'text': p['query_text'], \n",
    "                'bin_maj_label': p['prediction'][0],\n",
    "                'bin_one_label': p['prediction'][1],\n",
    "                'bin_all_label': p['prediction'][2], \n",
    "                'multi_maj_label':p['prediction'][3],\n",
    "                'disagree_bin_label': p['prediction'][4]} for p in prediction]\n",
    "    return pd.DataFrame(prediction, columns=prediction[0].keys())"
   ],
   "id": "5246177f2ab8dc18",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#do you want to compute the vector index?\n",
    "run_this = False"
   ],
   "id": "c9ba9a08a52ac48b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# First with the \"dbmdz/bert-base-german-uncased\" model",
   "id": "72c53fcd256a34c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if run_this:\n",
    "    predictions_Bert_5 = run_rag_pipeline(train_df, test_data, \"Bert\", top_k = 5)\n",
    "    predictions_Bert_5_df = data_to_dataframe(predictions_Bert_5)\n",
    "    predictions_Bert_10 = run_rag_pipeline(train_df, test_data, \"Bert\", top_k=10)\n",
    "    predictions_Bert_10_df = data_to_dataframe(predictions_Bert_10)\n",
    "    predictions_Bert_20 = run_rag_pipeline(train_df, test_data, \"Bert\", top_k=20)\n",
    "    predictions_Bert_20_df = data_to_dataframe(predictions_Bert_20)"
   ],
   "id": "fdbdf2b7056bf91e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T13:57:35.963909Z",
     "start_time": "2025-08-25T13:57:35.892579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('with k = 5')\n",
    "compute_f1(dev_df.iloc[:100], predictions_Bert_5_df)\n",
    "print('with k = 10')\n",
    "compute_f1(dev_df.iloc[:100], predictions_Bert_10_df) #performs best here\n",
    "print('with k = 20')\n",
    "compute_f1(dev_df.iloc[:100], predictions_Bert_20_df)"
   ],
   "id": "27fba6aa26bc3b86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with k = 5\n",
      "Dev set F1 score Bin Maj: 0.6504735195771761\n",
      "Dev set F1 score Bin One: 0.5367466666666667\n",
      "Dev set F1 score Bin All: 0.8348235294117647\n",
      "Dev set F1 score Multi Maj: 0.6423015873015874\n",
      "Dev set F1 score Disagree Bin: 0.632291543814129\n",
      "with k = 10\n",
      "Dev set F1 score Bin Maj: 0.7036011396011397\n",
      "Dev set F1 score Bin One: 0.5529845755581921\n",
      "Dev set F1 score Bin All: 0.8570327552986512\n",
      "Dev set F1 score Multi Maj: 0.7003333333333334\n",
      "Dev set F1 score Disagree Bin: 0.5868253968253968\n",
      "with k = 20\n",
      "Dev set F1 score Bin Maj: 0.7124080882352942\n",
      "Dev set F1 score Bin One: 0.5031111111111111\n",
      "Dev set F1 score Bin All: 0.8389743589743591\n",
      "Dev set F1 score Multi Maj: 0.6386732919254658\n",
      "Dev set F1 score Disagree Bin: 0.5875908099088692\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's also check a different aggregation mode:",
   "id": "2b17811ec2784708"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if run_this:\n",
    "    predictions_Bert_5_w = run_rag_pipeline(train_df, test_data, \"Bert\", top_k=5, aggregation='weighted')\n",
    "    predictions_Bert_5_w_df = data_to_dataframe(predictions_Bert_5_w)\n",
    "    predictions_Bert_10_w = run_rag_pipeline(train_df, test_data, \"Bert\", top_k=10, aggregation='weighted')\n",
    "    predictions_Bert_10_w_df = data_to_dataframe(predictions_Bert_10_w)\n",
    "    predictions_Bert_20_w = run_rag_pipeline(train_df, test_data, \"Bert\", top_k=20, aggregation='weighted')\n",
    "    predictions_Bert_20_w_df = data_to_dataframe(predictions_Bert_20_w)"
   ],
   "id": "99c648eeb8d0b391",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T14:00:02.382619Z",
     "start_time": "2025-08-25T14:00:02.341993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('with k = 5')\n",
    "compute_f1(dev_df.iloc[:100], predictions_Bert_5_w_df)\n",
    "print('with k = 10')\n",
    "compute_f1(dev_df.iloc[:100], predictions_Bert_10_w_df) #perfroms best here\n",
    "print('with k = 20')\n",
    "compute_f1(dev_df.iloc[:100], predictions_Bert_20_w_df)"
   ],
   "id": "aec816cd35d62278",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with k = 5\n",
      "Dev set F1 score Bin Maj: 0.6504735195771761\n",
      "Dev set F1 score Bin One: 0.5367466666666667\n",
      "Dev set F1 score Bin All: 0.8348235294117647\n",
      "Dev set F1 score Multi Maj: 0.29154429962052464\n",
      "Dev set F1 score Disagree Bin: 0.632291543814129\n",
      "with k = 10\n",
      "Dev set F1 score Bin Maj: 0.7227236467236468\n",
      "Dev set F1 score Bin One: 0.5471601703242712\n",
      "Dev set F1 score Bin All: 0.8722285714285715\n",
      "Dev set F1 score Multi Maj: 0.26563765182186233\n",
      "Dev set F1 score Disagree Bin: 0.5791387559808612\n",
      "with k = 20\n",
      "Dev set F1 score Bin Maj: 0.7211887382690303\n",
      "Dev set F1 score Bin One: 0.5031111111111111\n",
      "Dev set F1 score Bin All: 0.8389743589743591\n",
      "Dev set F1 score Multi Maj: 0.14662376779846661\n",
      "Dev set F1 score Disagree Bin: 0.5800913242009131\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Now with the \"intfloat/multilingual-e5-large\" model",
   "id": "c0ef2d7f61acd407"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if run_this:\n",
    "    predictions_e5_5 = run_rag_pipeline(train_df, test_data, \"notBert\", top_k = 5)\n",
    "    predictions_e5_5_df = data_to_dataframe(predictions_e5_5)\n",
    "    predictions_e5_10 = run_rag_pipeline(train_df, test_data, \"notBert\", top_k = 10)\n",
    "    predictions_e5_10_df = data_to_dataframe(predictions_e5_10)\n",
    "    predictions_e5_20 = run_rag_pipeline(train_df, test_data, \"notBert\", top_k = 20)\n",
    "    predictions_e5_20_df = data_to_dataframe(predictions_e5_20)"
   ],
   "id": "6e889def7d441153",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T14:05:03.109161Z",
     "start_time": "2025-08-25T14:05:03.001387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('with k = 5')\n",
    "compute_f1(dev_df.iloc[:100], predictions_e5_5_df) #performs best here\n",
    "print('with k = 10')\n",
    "compute_f1(dev_df.iloc[:100], predictions_e5_10_df)\n",
    "print('with k = 20')\n",
    "compute_f1(dev_df.iloc[:100], predictions_e5_20_df)"
   ],
   "id": "55e6adae1d19bcb8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with k = 5\n",
      "Dev set F1 score Bin Maj: 0.7029249011857708\n",
      "Dev set F1 score Bin One: 0.5956626506024096\n",
      "Dev set F1 score Bin All: 0.8341621621621621\n",
      "Dev set F1 score Multi Maj: 0.6412717536813922\n",
      "Dev set F1 score Disagree Bin: 0.5785291425083918\n",
      "with k = 10\n",
      "Dev set F1 score Bin Maj: 0.7135690396559962\n",
      "Dev set F1 score Bin One: 0.5674819541793075\n",
      "Dev set F1 score Bin All: 0.8188235294117647\n",
      "Dev set F1 score Multi Maj: 0.6366279069767442\n",
      "Dev set F1 score Disagree Bin: 0.5483636363636363\n",
      "with k = 20\n",
      "Dev set F1 score Bin Maj: 0.6420833333333335\n",
      "Dev set F1 score Bin One: 0.57984\n",
      "Dev set F1 score Bin All: 0.8238297872340425\n",
      "Dev set F1 score Multi Maj: 0.6428571428571428\n",
      "Dev set F1 score Disagree Bin: 0.6078817733990148\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if run_this:\n",
    "    predictions_e5_5_w = run_rag_pipeline(train_df, test_data, \"notBert\", top_k=5, aggregation='weighted')\n",
    "    predictions_e5_5_w_df = data_to_dataframe(predictions_e5_5_w)\n",
    "    predictions_e5_10_w = run_rag_pipeline(train_df, test_data, \"notBert\", top_k=10, aggregation='weighted')\n",
    "    predictions_e5_10_w_df = data_to_dataframe(predictions_e5_10_w)\n",
    "    predictions_e5_20_w = run_rag_pipeline(train_df, test_data, \"notBert\", top_k=20, aggregation='weighted')\n",
    "    predictions_e5_20_w_df = data_to_dataframe(predictions_e5_20_w)"
   ],
   "id": "2a800bcfa3c6da1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T14:09:49.828054Z",
     "start_time": "2025-08-25T14:09:49.791763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('with k = 5')\n",
    "compute_f1(dev_df.iloc[:100], predictions_e5_5_w_df)\n",
    "print('with k = 10')\n",
    "compute_f1(dev_df.iloc[:100], predictions_e5_10_w_df)\n",
    "print('with k = 20')\n",
    "compute_f1(dev_df.iloc[:100], predictions_e5_20_w_df) #performs best here"
   ],
   "id": "56959b23c0137e96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with k = 5\n",
      "Dev set F1 score Bin Maj: 0.7029249011857708\n",
      "Dev set F1 score Bin One: 0.5956626506024096\n",
      "Dev set F1 score Bin All: 0.8341621621621621\n",
      "Dev set F1 score Multi Maj: 0.5241558441558442\n",
      "Dev set F1 score Disagree Bin: 0.5785291425083918\n",
      "with k = 10\n",
      "Dev set F1 score Bin Maj: 0.7056043773835186\n",
      "Dev set F1 score Bin One: 0.5923187052598817\n",
      "Dev set F1 score Bin All: 0.8188235294117647\n",
      "Dev set F1 score Multi Maj: 0.5333224222585925\n",
      "Dev set F1 score Disagree Bin: 0.567085346215781\n",
      "with k = 20\n",
      "Dev set F1 score Bin Maj: 0.6676488095238095\n",
      "Dev set F1 score Bin One: 0.605739626227431\n",
      "Dev set F1 score Bin All: 0.8238297872340425\n",
      "Dev set F1 score Multi Maj: 0.5302641509433962\n",
      "Dev set F1 score Disagree Bin: 0.6079967360261118\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Conclusion",
   "id": "fa02d0112e6faee6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Pro: No issues with reproducibility here\n",
    "Contra: Results are worse compared to the results from \"comparisonAPI.ipynb\"."
   ],
   "id": "559991cce98e9e65"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's see what happens when we not only use RAG but also the API",
   "id": "be8ea5519fc65b2e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's load the API key",
   "id": "84395d880dde0c3f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-25T14:09:49.866225Z",
     "start_time": "2025-08-25T14:09:49.859759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY_25\")\n",
    "print(f\"API Key loaded: {OPENAI_API_KEY is not None}\")"
   ],
   "id": "819be7ddba8b1e76",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded: True\n"
     ]
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
